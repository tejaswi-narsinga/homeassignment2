Question 1: Cloud Computing for Deep Learning
Elasticity in cloud computing refers to the ability of a system to automatically scale up or down in response to changes in workload. Scalability, on the other hand, refers to the ability of a system to handle increased workload without a decrease in performance.
AWS SageMaker, Google Vertex AI, and Microsoft Azure Machine Learning Studio are all cloud-based platforms that provide deep learning capabilities. SageMaker provides a wide range of algorithms and frameworks, while Vertex AI provides a more streamlined and automated experience. Azure Machine Learning Studio provides a visual interface for building and deploying machine learning models.

Question 2: Convolution Operations with Different Parameters
Convolution operations can be performed with different stride and padding parameters. A stride of 1 and padding of "VALID" will result in a feature map that is smaller than the input data. A stride of 1 and padding of "SAME" will result in a feature map that is the same size as the input data. A stride of 2 and padding of "VALID" will result in a feature map that is half the size of the input data. A stride of 2 and padding of "SAME" will result in a feature map that is the same size as the input data.


Question 3: CNN Feature Extraction with Filters and Pooling
Edge detection can be performed using a Sobel filter. The Sobel filter is applied in both the x and y directions to detect edges in an image.
Max pooling and average pooling are both used to downsample feature maps in a CNN. Max pooling takes the maximum value in each window, while average pooling takes the average value in each window.


Question 4: Implementing and Comparing CNN Architectures
AlexNet is a CNN architecture that consists of five convolutional layers and three fully connected layers. The architecture uses ReLU activation and max pooling to downsample feature maps.
A residual block is a building block of a ResNet architecture. It consists of two convolutional layers with a skip connection that adds the input to the output. The ResNet architecture uses a number of residual blocks to build a deep CNN.
